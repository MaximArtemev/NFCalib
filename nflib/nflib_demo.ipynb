{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nflib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-97cc10f62661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from nflib.flows import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mAffineConstantFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAffineHalfFlow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mSlowMAF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIAF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInvertible1x1Conv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nflib'"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.distributions import MultivariateNormal, Uniform, TransformedDistribution, SigmoidTransform\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from nflib.flows import (\n",
    "    AffineConstantFlow, ActNorm, AffineHalfFlow, \n",
    "    SlowMAF, MAF, IAF, Invertible1x1Conv,\n",
    "    NormalizingFlow, NormalizingFlowModel,\n",
    ")\n",
    "from nflib.spline_flows import NSF_AR, NSF_CL\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightweight datasets\n",
    "import pickle\n",
    "from sklearn import datasets\n",
    "\n",
    "class DatasetSIGGRAPH:\n",
    "    \"\"\" \n",
    "    haha, found from Eric https://blog.evjang.com/2018/01/nf2.html\n",
    "    https://github.com/ericjang/normalizing-flows-tutorial/blob/master/siggraph.pkl\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        with open('siggraph.pkl', 'rb') as f:\n",
    "            XY = np.array(pickle.load(f), dtype=np.float32)\n",
    "            XY -= np.mean(XY, axis=0) # center\n",
    "        self.XY = torch.from_numpy(XY)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        X = self.XY[np.random.randint(self.XY.shape[0], size=n)]\n",
    "        return X\n",
    "\n",
    "class DatasetMoons:\n",
    "    \"\"\" two half-moons \"\"\"\n",
    "    def sample(self, n):\n",
    "        moons = datasets.make_moons(n_samples=n, noise=0.05)[0].astype(np.float32)\n",
    "        return torch.from_numpy(moons)\n",
    "\n",
    "class DatasetMixture:\n",
    "    \"\"\" 4 mixture of gaussians \"\"\"\n",
    "    def sample(self, n):\n",
    "        assert n%4 == 0\n",
    "        r = np.r_[np.random.randn(n // 4, 2)*0.5 + np.array([0, -2]),\n",
    "                  np.random.randn(n // 4, 2)*0.5 + np.array([0, 0]),\n",
    "                  np.random.randn(n // 4, 2)*0.5 + np.array([2, 2]),\n",
    "                  np.random.randn(n // 4, 2)*0.5 + np.array([-2, 2])]\n",
    "        return torch.from_numpy(r.astype(np.float32))\n",
    "\n",
    "d = DatasetMoons()\n",
    "#d = DatasetMixture()\n",
    "#d = DatasetSIGGRAPH()\n",
    "\n",
    "x = d.sample(128)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(x[:,0], x[:,1], s=5, alpha=0.5)\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a model\n",
    "#prior = MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "prior = TransformedDistribution(Uniform(torch.zeros(2), torch.ones(2)), SigmoidTransform().inv) # Logistic distribution\n",
    "\n",
    "# RealNVP\n",
    "# flows = [AffineHalfFlow(dim=2, parity=i%2) for i in range(9)]\n",
    "\n",
    "# NICE\n",
    "# flows = [AffineHalfFlow(dim=2, parity=i%2, scale=False) for i in range(4)]\n",
    "# flows.append(AffineConstantFlow(dim=2, shift=False))\n",
    "\n",
    "# SlowMAF (MAF, but without any parameter sharing for each dimension's scale/shift)\n",
    "# flows = [SlowMAF(dim=2, parity=i%2) for i in range(4)]\n",
    "\n",
    "# MAF (with MADE net, so we get very fast density estimation)\n",
    "# flows = [MAF(dim=2, parity=i%2) for i in range(4)]\n",
    "\n",
    "# IAF (with MADE net, so we get very fast sampling)\n",
    "# flows = [IAF(dim=2, parity=i%2) for i in range(3)]\n",
    "\n",
    "# insert ActNorms to any of the flows above\n",
    "# norms = [ActNorm(dim=2) for _ in flows]\n",
    "# flows = list(itertools.chain(*zip(norms, flows)))\n",
    "\n",
    "# Glow paper\n",
    "# flows = [Invertible1x1Conv(dim=2) for i in range(3)]\n",
    "# norms = [ActNorm(dim=2) for _ in flows]\n",
    "# couplings = [AffineHalfFlow(dim=2, parity=i%2, nh=32) for i in range(len(flows))]\n",
    "# flows = list(itertools.chain(*zip(norms, flows, couplings))) # append a coupling layer after each 1x1\n",
    "\n",
    "# Neural splines, coupling\n",
    "nfs_flow = NSF_CL if True else NSF_AR\n",
    "flows = [nfs_flow(dim=2, K=8, B=3, hidden_dim=16) for _ in range(3)]\n",
    "convs = [Invertible1x1Conv(dim=2) for _ in flows]\n",
    "norms = [ActNorm(dim=2) for _ in flows]\n",
    "flows = list(itertools.chain(*zip(norms, convs, flows)))\n",
    "\n",
    "# construct the model\n",
    "model = NormalizingFlowModel(prior, flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5) # todo tune WD\n",
    "print(\"number of params: \", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for k in range(1000):\n",
    "    x = d.sample(128)\n",
    "    \n",
    "    zs, prior_logprob, log_det = model(x)\n",
    "    logprob = prior_logprob + log_det\n",
    "    loss = -torch.sum(logprob) # NLL\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if k % 100 == 0:\n",
    "        print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "x = d.sample(128)\n",
    "zs, prior_logprob, log_det = model(x)\n",
    "z = zs[-1]\n",
    "\n",
    "x = x.detach().numpy()\n",
    "z = z.detach().numpy()\n",
    "p = model.prior.sample([128, 2]).squeeze()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(p[:,0], p[:,1], c='g', s=5)\n",
    "plt.scatter(z[:,0], z[:,1], c='r', s=5)\n",
    "plt.scatter(x[:,0], x[:,1], c='b', s=5)\n",
    "plt.legend(['prior', 'x->z', 'data'])\n",
    "plt.axis('scaled')\n",
    "plt.title('x -> z')\n",
    "\n",
    "zs = model.sample(128*8)\n",
    "z = zs[-1]\n",
    "z = z.detach().numpy()\n",
    "plt.subplot(122)\n",
    "plt.scatter(x[:,0], x[:,1], c='b', s=5, alpha=0.5)\n",
    "plt.scatter(z[:,0], z[:,1], c='r', s=5, alpha=0.5)\n",
    "plt.legend(['data', 'z->x'])\n",
    "plt.axis('scaled')\n",
    "plt.title('z -> x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the step-wise flow in the full net\n",
    "from matplotlib import collections  as mc\n",
    "\n",
    "# plot the coordinate warp\n",
    "ng = 20\n",
    "xx, yy = np.linspace(-3, 3, ng), np.linspace(-3, 3, ng)\n",
    "xv, yv = np.meshgrid(xx, yy)\n",
    "xy = np.stack([xv, yv], axis=-1)\n",
    "in_circle = np.sqrt((xy**2).sum(axis=2)) <= 3 # seems appropriate since we use radial distributions as priors\n",
    "xy = xy.reshape((ng*ng, 2))\n",
    "xy = torch.from_numpy(xy.astype(np.float32))\n",
    "\n",
    "zs, log_det = model.backward(xy)\n",
    "\n",
    "backward_flow_names = [type(f).__name__ for f in model.flow.flows[::-1]]\n",
    "nz = len(zs)\n",
    "for i in range(nz - 1):\n",
    "    z0 = zs[i].detach().numpy()\n",
    "    z1 = zs[i+1].detach().numpy()\n",
    "    \n",
    "    # plot how the samples travel at this stage\n",
    "    figs, axs = plt.subplots(1, 2, figsize=(6, 3))\n",
    "    #plt.figure(figsize=(20,10))\n",
    "    axs[0].scatter(z0[:,0], z0[:, 1], c='r', s=3)\n",
    "    axs[0].scatter(z1[:,0], z1[:, 1], c='b', s=3)\n",
    "    axs[0].quiver(z0[:,0], z0[:,1], z1[:,0] - z0[:,0], z1[:,1] - z0[:,1], units='xy', scale=1, alpha=0.5)\n",
    "    axs[0].axis([-3, 3, -3, 3])\n",
    "    axs[0].set_title(\"layer %d -> %d (%s)\" % (i, i+1, backward_flow_names[i]))\n",
    "    \n",
    "    q = z1.reshape((ng, ng, 2))\n",
    "    # y coords\n",
    "    p1 = np.reshape(q[1:,:,:], (ng**2-ng,2))\n",
    "    p2 = np.reshape(q[:-1,:,:], (ng**2-ng,2))\n",
    "    inc = np.reshape(in_circle[1:,:] | in_circle[:-1,:], (ng**2-ng,))\n",
    "    p1, p2 = p1[inc], p2[inc]\n",
    "    lcy = mc.LineCollection(zip(p1, p2), linewidths=1, alpha=0.5, color='k')\n",
    "    # x coords\n",
    "    p1 = np.reshape(q[:,1:,:], (ng**2-ng,2))\n",
    "    p2 = np.reshape(q[:,:-1,:], (ng**2-ng,2))\n",
    "    inc = np.reshape(in_circle[:,1:] | in_circle[:,:-1], (ng**2-ng,))\n",
    "    p1, p2 = p1[inc], p2[inc]\n",
    "    lcx = mc.LineCollection(zip(p1, p2), linewidths=1, alpha=0.5, color='k')\n",
    "    # draw the lines\n",
    "    axs[1].add_collection(lcy)\n",
    "    axs[1].add_collection(lcx)\n",
    "    axs[1].axis([-3, 3, -3, 3])\n",
    "    axs[1].set_title(\"grid warp at the end of %d\" % (i+1,))\n",
    "    \n",
    "    # draw the data too\n",
    "    plt.scatter(x[:,0], x[:,1], c='r', s=5, alpha=0.5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train and render\n",
    "# code duplication because it's very late at night now and i'm tired\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "ng = 20\n",
    "xx, yy = np.linspace(-3, 3, ng), np.linspace(-3, 3, ng)\n",
    "xv, yv = np.meshgrid(xx, yy)\n",
    "xy = np.stack([xv, yv], axis=-1)\n",
    "in_circle = np.sqrt((xy**2).sum(axis=2)) <= 3\n",
    "xy = xy.reshape((ng*ng, 2))\n",
    "xy = torch.from_numpy(xy.astype(np.float32))\n",
    "\n",
    "xval = d.sample(128*5)\n",
    "\n",
    "model.train()\n",
    "for k in range(500):\n",
    "    \n",
    "    # sample\n",
    "    x = d.sample(128)\n",
    "    \n",
    "    # train a bit\n",
    "    zs, prior_logprob, log_det = model(x)\n",
    "    logprob = prior_logprob + log_det\n",
    "    loss = -torch.sum(logprob) # NLL\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if k % 10 == 0:\n",
    "        # vis\n",
    "        zs, log_det = model.backward(xy)\n",
    "        backward_flow_names = [type(f).__name__ for f in model.flow.flows[::-1]]\n",
    "        nz = len(zs)\n",
    "        i = nz - 1 - 1\n",
    "\n",
    "        z0 = zs[i].detach().numpy()\n",
    "        z1 = zs[i+1].detach().numpy()\n",
    "\n",
    "        # plot how the samples travel at this stage\n",
    "        ss = 0.1\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        outer = gridspec.GridSpec(1, 2, wspace=ss, hspace=ss)\n",
    "        inner1 = gridspec.GridSpecFromSubplotSpec(3, 3, subplot_spec=outer[0], wspace=ss, hspace=ss)\n",
    "        inner2 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=outer[1], wspace=ss, hspace=ss)\n",
    "        \n",
    "        backward_flow_names = [type(f).__name__ for f in model.flow.flows[::-1]]\n",
    "        nz = len(zs)\n",
    "        for i in range(min(nz-1, 9)):\n",
    "            ax = plt.Subplot(fig, inner1[i])\n",
    "            z0 = zs[i].detach().numpy()\n",
    "            z1 = zs[i+1].detach().numpy()\n",
    "            ax.scatter(z0[:,0], z0[:, 1], c='r', s=1, alpha=0.5)\n",
    "            ax.scatter(z1[:,0], z1[:, 1], c='b', s=1, alpha=0.5)\n",
    "            ax.quiver(z0[:,0], z0[:,1], z1[:,0] - z0[:,0], z1[:,1] - z0[:,1], units='xy', scale=1, alpha=0.5)\n",
    "            ax.axis([-3, 3, -3, 3])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_xticklabels([])\n",
    "            #ax.set_title(\"layer %d -> %d (%s)\" % (i, i+1, backward_flow_names[i]))\n",
    "            fig.add_subplot(ax)\n",
    "        \n",
    "        ax = plt.Subplot(fig, inner2[0])\n",
    "        q = z1.reshape((ng, ng, 2))\n",
    "        # y coords\n",
    "        p1 = np.reshape(q[1:,:,:], (ng**2-ng,2))\n",
    "        p2 = np.reshape(q[:-1,:,:], (ng**2-ng,2))\n",
    "        inc = np.reshape(in_circle[1:,:] | in_circle[:-1,:], (ng**2-ng,))\n",
    "        p1, p2 = p1[inc], p2[inc]\n",
    "        lcy = mc.LineCollection(zip(p1, p2), linewidths=1, alpha=0.5, color='k')\n",
    "        # x coords\n",
    "        p1 = np.reshape(q[:,1:,:], (ng**2-ng,2))\n",
    "        p2 = np.reshape(q[:,:-1,:], (ng**2-ng,2))\n",
    "        inc = np.reshape(in_circle[:,1:] | in_circle[:,:-1], (ng**2-ng,))\n",
    "        p1, p2 = p1[inc], p2[inc]\n",
    "        lcx = mc.LineCollection(zip(p1, p2), linewidths=1, alpha=0.5, color='k')\n",
    "        # draw the lines\n",
    "        ax.add_collection(lcy)\n",
    "        ax.add_collection(lcx)\n",
    "        ax.axis([-3, 3, -3, 3])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        #ax.set_title(\"grid warp at the end of %d\" % (i+1,))\n",
    "        fig.add_subplot(ax)\n",
    "        \n",
    "        # draw the data too\n",
    "        plt.scatter(xval[:,0], xval[:,1], c='r', s=5, alpha=0.5)\n",
    "        \n",
    "        break\n",
    "        #fname = 'out/step_%04d.png' % (k,)\n",
    "        #plt.savefig(fname, dpi=200)\n",
    "        #print(\"saved\", fname, 'loss', loss.item())\n",
    "        #plt.close(fig)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
